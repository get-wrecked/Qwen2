{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ed478b-d82d-422c-985f-021238a381b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karthick/finetuning/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/karthick/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4eb62a7-54e4-45b1-bc6d-bdf2606a9ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "542fd2ff-ee5e-43d8-94f9-3beb6ccf00c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8000d88-d9c3-4198-856d-2e9fb5635c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|███████████████████████████████████████████| 4/4 [00:04<00:00,  1.19s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed582ec-7698-4403-a37d-041c47026135",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fcb921-476d-49c3-b5c9-141047d3a2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['NAME', 'CONVERSATION', 'TASK'],\n",
      "    num_rows: 30200\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "dataset_name = \"tryhighlight/task_dataset\"\n",
    "#Importing the dataset\n",
    "input_dataset = load_dataset(dataset_name, split=\"train\")\n",
    "print (input_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1bde4c0-62e0-4770-8085-159cb7592e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"The user will provide his/her full name followed by an email thread from their inbox that contains one or more email conversations. Looking at the conversation, detect if there are any TODOs that the user has to complete as a result of the conversation. If yes, just provide the short single line task that can be directly added to the todo list. If there is no task detected as a TODO, just output the exact phrase \\\"No task\\\". If the conversation is about a promotional or advertisement related, please output \\\"No task\\\". If the conversation is directed or addressed to someone else, then output \\\"No task\\\". Just provide the short single line task or the phrase \\\"No task\\\", no other explanation is needed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ae94469-bc5b-468d-87f2-d584b6a58f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8dcf0e6-c296-4924-a9da-ac387293d33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=4): 100%|████████████████████████████████| 30200/30200 [00:09<00:00, 3177.60 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset after filtering: 17834 samples\n"
     ]
    }
   ],
   "source": [
    "def check_length(row):\n",
    "    # This function checks if the tokenized length is within the max length allowed\n",
    "    input_content = tokenizer1.encode(system_prompt + row[\"NAME\"] + row[\"CONVERSATION\"] + row[\"TASK\"],\n",
    "                                        add_special_tokens=True,\n",
    "                                        truncation=False,\n",
    "                                        return_length=True,\n",
    "                                        max_length=None)\n",
    "    return len(input_content) <= max_len - 20 # extra 20 tokens for the chat template\n",
    "\n",
    "# Filter the dataset to exclude entries that are too long\n",
    "input_dataset = input_dataset.filter(check_length, num_proc=4)\n",
    "print(f\"Size of the dataset after filtering: {len(input_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d3e9538-5bb1-49ab-a67a-04ef13c7a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=input_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecb0c70f-25da-4584-b0bf-68b70ca6688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11d92ed1-689f-44e0-89bd-70593c721ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b18b732a-f203-4824-8617-98258692db87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['NAME', 'CONVERSATION', 'TASK'],\n",
       "        num_rows: 90\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['NAME', 'CONVERSATION', 'TASK'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ece3248-84ab-426b-9abc-9999efcc8d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Approve Access Request for matt.smith@enron.com\n",
      "Inference output :  Approve access request for matt.smith@enron.com \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Review the 1mm laddered muni portfolio proposal in the attached Excel file.\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Approve expense report \"Rostant 112001\" for Justin K Rostant.\n",
      "Inference output :  Review Rostant 112001 expense report. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Confirm if you need the buy/sell breakouts broken down by product type.\n",
      "Inference output :  Buy/sell breakouts by product type \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Provide book list at Amazon.com to Karen.\n",
      "Inference output :  John Arnold\n",
      "\n",
      "The task is: \"John, I need your book list at Amazon.com this week \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Schedule a meeting with Mike Grigsby to discuss increasing liquidity in the West Basis on EOL.\n",
      "Inference output :  Increase EOL liquidity in West Basis. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  Phillip Allen, No task. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Send address change to Pop's Wines & Spirits if you wish to continue to receive their catalog.\n",
      "Inference output :  John Arnold, TODO: Send address change ASAP. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  John Arnold, please add \"Re-establish ENA's account with Paribas\" to your to \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  Buy winter physical and sell Oct and go long Feb physical \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Execute and send the Grande Communications Service Agreement to Hunter Williams.\n",
      "Inference output :  Phillip Allen, \"Please execute and send to: Grande Communications, 401 Carlson Circle, San \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Send book list from Amazon.com\n",
      "Inference output :  Get book list from amazon.com \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Buy 1095 Jan 02 from Williams and sell to Koch\n",
      "Inference output :  John Arnold\n",
      "\n",
      "Task: Buy 1095 Jan 02 from Williams, sell to Koch \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Please reply to Greg about Friday and property visits.\n",
      "Inference output :  \"Park the money until we find the right investment\" \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  John Arnold\n",
      "\n",
      "Task: Sell 872 NOV \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Please let me know if you still need Curve Shift.\n",
      "Inference output :  Phillip Allen, \n",
      "\n",
      "The task that needs to be completed is: \"add the prior day for \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Call Todd Apple.\n",
      "Inference output :  Call Foster \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  John Arnold\n",
      "No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Review and act upon access request for matt.smith@enron.com\n",
      "Inference output :  Review and approve the access request. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  Complete TAS Futures delivery to EDF MAN #5055 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Respond to Caroline regarding the most recent Bloomberg from Ospraie.\n",
      "Inference output :  John Arnold \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Approve access request for matt.smith@enron.com\n",
      "Inference output :  Approve request for matt.smith@enron.com. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  Create a list of Enron positions. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  John Arnold, No task. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  Review the list of employees for ECS access. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Call Steve Lafontaine ASAP.\n",
      "Inference output :  Follow up with Steve Lafontaine \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Approve access request for matt.smith@enron.com.\n",
      "Inference output :  Phillip Allen, \"Click http://itcapps.corp.enron.com/srrs/auth \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Schedule 45 minutes for a meeting with Jonathan Whitehead and Eric Gonzales regarding LNG and US Natgas market.\n",
      "Inference output :  Update Atlantic basin LNG situation \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  John Arnold\n",
      "\n",
      "The task that can be directly added to the todo list is: \"Disconnect toll free \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Approve pending expense reports.\n",
      "Inference output :  Review JRostant 10/24/01 report \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  Take photos of NYMEX \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  Phillip Allen, No task. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  John Arnold\n",
      "\n",
      "No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  John Arnold \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  John Arnold\n",
      "\n",
      "No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Send Mery a definition of Intra-Month Risk.\n",
      "Inference output :  Phillip Allen\n",
      "\n",
      "Task: Send a definition of Intra-Month Risk \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  John Arnold\n",
      "\n",
      "No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Approve the expense report from James W Reitmeyer\n",
      "Inference output :  Review James W Reitmeyer's expense report. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  John Arnold\n",
      "\n",
      "No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  Task: Increase security presence at Enron Center. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  Phillip Allen: No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Confirm convenient time for EOL code update with Chris Jeska.\n",
      "Inference output :  Provide task: \"Check with Chris Jeska for EOL workstation update timing\" \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Provide a copy of the current title policy to Bob Huntley.\n",
      "Inference output :  Phillip Allen, the task is: \"Review title policy for easements\". \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Create slide for John Sheriff.\n",
      "Inference output :  \"Create slide\" \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  John Arnold, No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  Phillip Allen: \n",
      "\n",
      "Task: direct comments to James Bruce about the report. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Approve expense reports from Justin K Rostant.\n",
      "Inference output :  \"Review Rostant 112001 expense report\" \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  tenn+3 200 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Approve pending expense reports.\n",
      "Inference output :  Review Quigley 100301 expense report \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  John Arnold\n",
      "\n",
      "No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Contact Lyndon A. Taylor as soon as possible.\n",
      "Inference output :  John Arnold, Touch base with Lyndon Taylor as soon as possible. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  Update tb to 9.5 for 250. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  Follow up on Gas P&L by day \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Sign the First Amendment to Contract and fax a copy to Michelle.\n",
      "Inference output :  Phillip Allen\n",
      "\n",
      "The task is: \"Please sign the Amendment at your earliest convenience and fax a \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Figure out what John Lavorato lost last week.\n",
      "Inference output :  Task: Figure out what I lost last week. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  Phillip Allen\n",
      "\n",
      "No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Swap out some cal 04 with Steve.\n",
      "Inference output :  Follow up with Steve Lengkeek Jr. to swap out Cal 04. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  Take action on NYMEX margin increase \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Review and sign the clean version of the First Amendment to Contract.\n",
      "Inference output :  Phillip Allen\n",
      "\n",
      "The task is: Sign the First Amendment to Contract. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  John Arnold\n",
      "\n",
      "No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Attend the Risk Management Simulation Meeting on 10/30/01\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Please provide preferred method to handle draw request and contract signing.\n",
      "Inference output :  Please complete \"Discuss funds transfer and signing contracts\". \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Confirm you are okay with sending the proposal Bob Shults mentioned.\n",
      "Inference output :  John Arnold\n",
      "\n",
      "Task: Review proposal from Nymex and provide feedback. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  No task \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  Task : Forward phone number to Daniel McElduff or call Bo Collins at 212-299-2260\n",
      "Inference output :  I cannot help you with that. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :  No task\n",
      "Inference output :  John Arnold\n",
      "\n",
      "No task \n",
      "\n",
      "Expected output :  Task : Let Jeff know if you have an interest in the three property deals he will fax.\n",
      "Inference output :  Phillip Allen, No task. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in dataset[\"train\"]:\n",
    "    messages = [ \n",
    "        {\"role\": \"system\", \"content\": system_prompt}, \n",
    "        {\"role\": \"user\", \"content\": \"My name is \" + row[\"NAME\"] + \" \\n\" + row[\"CONVERSATION\"]}\n",
    "    ]\n",
    "    # print (messages)\n",
    "    # print ('name : ',  row[\"NAME\"])\n",
    "    # print ('CONVERSATION :', row[\"CONVERSATION\"])\n",
    "    outputs = pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=20,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=1.0,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    print ('Expected output : ', row['TASK'])\n",
    "    print ('Inference output : ', outputs[0]['generated_text'][-1][\"content\"], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de0550-10bc-4ba5-9fcc-17cb25b39a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

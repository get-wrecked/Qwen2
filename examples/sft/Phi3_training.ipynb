{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c0952-ce89-4c8d-8424-211180846df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import mlflow\n",
    "import argparse\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "import torch\n",
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e47f4-a43f-4354-9019-038810346cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5aeaa-f535-41f4-9d1b-47f130ffddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"tryhighlight/task_dataset\", split='train')\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74996232-a2ff-4026-852c-535da783115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c80494-77c8-4723-9f13-f9aa6b4b9c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_json(f\"data/train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ae916b-9e47-4203-b7bb-762553cdf61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_dataset(\"tryhighlight/task_dataset\", split='test')\n",
    "\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5381e3-d044-4266-abf7-98af22f419f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786de928-f5f3-4362-aaaa-179f8235f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.to_json(f\"data/eval.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3cbb1-b191-47bb-a8ab-47d28a2a40be",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "###################\n",
    "# Hyper-parameters\n",
    "###################\n",
    "training_config = {\n",
    "    \"bf16\": True,\n",
    "    \"do_eval\": False,\n",
    "    \"learning_rate\": 5.0e-06,\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_steps\": 20,\n",
    "    \"logging_strategy\": \"steps\",\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_train_epochs\": 5,\n",
    "    \"max_steps\": -1,\n",
    "    \"output_dir\": \"./checkpoint_dir\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"per_device_eval_batch_size\": 1,\n",
    "    \"per_device_train_batch_size\": 1,\n",
    "    \"remove_unused_columns\": True,\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"gradient_checkpointing_kwargs\":{\"use_reentrant\": False},\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"warmup_ratio\": 0.2,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f475e-adda-4775-ab0a-180abaa58e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = {\n",
    "    \"r\": 16,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"CAUSAL_LM\",\n",
    "    \"target_modules\": \"all-linear\",\n",
    "    \"modules_to_save\": None,\n",
    "}\n",
    "train_conf = TrainingArguments(**training_config)\n",
    "peft_conf = LoraConfig(**peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b9d9a9-7d1e-494f-a607-d468ecd73b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Setup logging\n",
    "###############\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "log_level = train_conf.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "# Log on each process a small summary\n",
    "logger.warning(\n",
    "    f\"Process rank: {train_conf.local_rank}, device: {train_conf.device}, n_gpu: {train_conf.n_gpu}\"\n",
    "    + f\" distributed training: {bool(train_conf.local_rank != -1)}, 16-bits training: {train_conf.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {train_conf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df237d-0a1d-496e-b042-58a3a7c4e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Modle Loading\n",
    "################\n",
    "checkpoint_path = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# checkpoint_path = \"microsoft/Phi-3-mini-128k-instruct\"\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation=\"flash_attention_2\",  # loading the model with flash-attenstion support\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "tokenizer.model_max_length = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c192a57a-059b-42ec-be19-dd882b516aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e20a0-7359-4905-8d2c-1e9c332689cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee5851f-1714-45bd-9d8e-c16f8aedef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.unk_token  # use unk rather than eos token to prevent endless generation\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52796cbb-44ec-4286-be88-32e966af4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful ai assistant. User will provide full name followed by some email or messaging conversation seen on his/her computer screen. Looking at the conversation, detect if there are any TODOs that the above user has to complete as a result of the conversation. If yes, just provide the short single line task that can be directly added to the todo list. If there is no task detected as a TODO, just output the exact phrase \\\"No task\\\". If the conversation is about a promotional or advertisement related, please output \\\"No task\\\". If the conversation is directed or addressed to someone else, then output \\\"No task\\\".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c57a77-62d0-47b6-98e9-fc191ea3b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Data Processing\n",
    "##################\n",
    "def apply_chat_template(\n",
    "    example,\n",
    "    tokenizer,\n",
    "):\n",
    "    row_json = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"My name is \" + example[\"NAME\"] + \" \\n\" + example[\"CONVERSATION\"]},\n",
    "        {\"role\": \"assistant\", \"content\": example[\"TASK\"]}]\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(\n",
    "        row_json, tokenize=False, add_generation_prompt=False)\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ffe2a-282b-4d29-bdac-ae9c96aa2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset('json', data_files='data/train.jsonl', split='train')\n",
    "test_dataset = load_dataset('json', data_files='data/eval.jsonl', split='train')\n",
    "column_names = list(train_dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f1bc5-044a-43d5-ab0f-1f167d921e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_length(row):\n",
    "    # This function checks if the tokenized length is within the max length allowed\n",
    "    input_content = tokenizer.encode(system_prompt + row[\"NAME\"] + row[\"CONVERSATION\"] + row[\"TASK\"],\n",
    "                                        add_special_tokens=True,\n",
    "                                        truncation=False,\n",
    "                                        return_length=True,\n",
    "                                        max_length=None)\n",
    "    return len(input_content) <= tokenizer.model_max_length - 20 # extra 20 tokens for the chat template\n",
    "\n",
    "# Filter the dataset to exclude entries that are too long\n",
    "train_dataset = train_dataset.filter(check_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e55d66-90ad-4771-ac6a-8bda599229af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a87945-3fbb-4d6c-8877-78fa9e289df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.filter(check_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee9339c-3f3b-4904-ab4a-7391d96d5ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5136b-3174-4aa4-882a-cf026e3673c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_dataset = train_dataset.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    num_proc=10,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Applying chat template to train_sft\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189c919a-7a2b-4379-9a44-2efbc53662d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_dataset = test_dataset.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    num_proc=10,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Applying chat template to test_sft\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b19c70-d0a3-4c18-9b41-1bff0024cbea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceeb9a7-2d8a-4c2c-836a-ce68f49f2ab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a5b55-dcc3-4cb7-8b44-1aa8da61a6ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=train_conf,\n",
    "    peft_config=peft_conf,\n",
    "    train_dataset=processed_train_dataset,\n",
    "    eval_dataset=processed_test_dataset,\n",
    "    max_seq_length=tokenizer.model_max_length,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11607dd5-7d32-4bd4-9508-7fd2ffba47f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25892778-720b-48c8-9048-20a6deefc04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09508a6-e28d-4c89-9bdb-26044949d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2292e15-6151-4e64-bc1f-a0e421e70747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
